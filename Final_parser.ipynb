{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model testing"
      ],
      "metadata": {
        "id": "Lh342ojCKZVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "10QqE9YaB-ci"
      },
      "outputs": [],
      "source": [
        "##Install necessary packages\n",
        "\n",
        "%%capture\n",
        "%pip install -U pip setuptools wheel\n",
        "%pip install -U spacy\n",
        "%pip install spacy-transformers\n",
        "!python -m spacy download en_core_web_trf\n",
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P7Pp9Sc1B-cl"
      },
      "outputs": [],
      "source": [
        "##download necessary libraries\n",
        "\n",
        "import os\n",
        "import re\n",
        "import spacy\n",
        "import PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to convert pdf resume to text format."
      ],
      "metadata": {
        "id": "svN0KjnDJzt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##pdf to text conversion\n",
        "\n",
        "def convert_pdf_to_text(file_path):\n",
        "  # Open the PDF file\n",
        "  with open(file_path, 'rb') as pdf_file:\n",
        "  # Create a PdfReader object to read the PDF file\n",
        "    reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "    # Initialize an empty string to store the extracted text\n",
        "    text = \"\"\n",
        "\n",
        "    # Iterate through each page in the PDF file\n",
        "    for page in reader.pages:\n",
        "    # Extract the text from the current page and append it to the 'text' string\n",
        "      text += page.extract_text()\n",
        "  return text"
      ],
      "metadata": {
        "id": "uvp_2NDTmPSb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to do some text preprocessing"
      ],
      "metadata": {
        "id": "FAqyRR_rJ591"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###some preprocessing\n",
        "\n",
        "lemm=spacy.load('en_core_web_trf')\n",
        "\n",
        "# lemmatization\n",
        "def lemmatize(words):\n",
        "\n",
        "    words= lemm(words)\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "\n",
        "        lemmas.append(word.lemma_)\n",
        "    return lemmas\n",
        "#converting them into string\n",
        "def listtostring(s):\n",
        "    str1=' '\n",
        "    return (str1.join(s))\n",
        "\n",
        "def clean_text(input):\n",
        "\n",
        "    lemmas=lemmatize(input)\n",
        "    return listtostring(lemmas)"
      ],
      "metadata": {
        "id": "rdAQsIV_tPEo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load your fine-tuned model-best on pre-trained BERT base model"
      ],
      "metadata": {
        "id": "J2iNj64YKBRl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SS-7ala1B-cr"
      },
      "outputs": [],
      "source": [
        "##load transformer_model/model-best which is fine tuned on BERT-base-cased\n",
        "\n",
        "nlp = spacy.load('/content/drive/MyDrive/Dissertation/transformer_model/model-best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dHFrS48nB-cs"
      },
      "outputs": [],
      "source": [
        "##Named Entity Recognition (NER) using spaCy on the Text Document\n",
        "def textandentities(cleaned_text):\n",
        "  for doc in nlp.pipe([cleaned_text], disable=[\"tagger\", \"parser\"]):\n",
        "    for ent in doc.ents:\n",
        "      text_name = re.sub('[^A-Za-z0-9]+', ' ', ent.text).strip()\n",
        "      print((text_name,ent.label_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Parser which takes pdf resume as input and extracts resume entities"
      ],
      "metadata": {
        "id": "zqHrDh4sKOTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##integrate all the functions above to make the final parser\n",
        "\n",
        "def final_parser(pdf_file):\n",
        "  text_file= convert_pdf_to_text(pdf_file)\n",
        "  cleaned_text= clean_text(text_file)\n",
        "  textandentities(cleaned_text)"
      ],
      "metadata": {
        "id": "xm_6bRIAG4Pm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##test on a new unseen resume pdf\n",
        "\n",
        "final_parser('/content/83816738.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMCtJzRHH_UW",
        "outputId": "24f02ae7-b7d2-491e-e411-d3a33ed04485"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('INFORMATION TECHNOLOGY INTERN', 'JOB TITLE')\n",
            "('CSS3', 'SKILL')\n",
            "('Bootstrap', 'SKILL')\n",
            "('SASS', 'SKILL')\n",
            "('LESS', 'SKILL')\n",
            "('JavaScript', 'SKILL')\n",
            "('jQuery', 'SKILL')\n",
            "('Java J2EE', 'SKILL')\n",
            "('JavaScript', 'SKILL')\n",
            "('Android', 'SKILL')\n",
            "('HTML', 'SKILL')\n",
            "('CSS', 'SKILL')\n",
            "('SQL', 'SKILL')\n",
            "('C', 'SKILL')\n",
            "('C framework', 'SKILL')\n",
            "('ReactJS', 'SKILL')\n",
            "('jQuery', 'SKILL')\n",
            "('Bootstrap', 'SKILL')\n",
            "('Selenium WebDriver', 'SKILL')\n",
            "('Cucumber database', 'SKILL')\n",
            "('MySQL', 'SKILL')\n",
            "('PostgreSQL', 'SKILL')\n",
            "('Oracle', 'SKILL')\n",
            "('H2 build tool', 'SKILL')\n",
            "('Gradle', 'SKILL')\n",
            "('Maven', 'SKILL')\n",
            "('Agile scrum', 'SKILL')\n",
            "('Waterfall', 'SKILL')\n",
            "('tdd', 'SKILL')\n",
            "('clean coding', 'SKILL')\n",
            "('continuous delivery architecture', 'SKILL')\n",
            "('Single Page application', 'SKILL')\n",
            "('REST', 'SKILL')\n",
            "('client server', 'SKILL')\n",
            "('SVN', 'SKILL')\n",
            "('Git Cloud', 'SKILL')\n",
            "('XML', 'SKILL')\n",
            "('05 2017 to 08 2017', 'EXPERIENCE')\n",
            "('05 2014 to 06 2016', 'EXPERIENCE')\n",
            "('Java Developer Intern 03 2014 to 05 2014', 'EXPERIENCE')\n",
            "('software developer Intern 01 2013 to 10 2013', 'EXPERIENCE')\n",
            "('Master of Science Computer Science', 'EDUCATION')\n",
            "('Lamar University', 'EDUCATION')\n",
            "('Bachelor of Engineering Electronics and Communication Engineering', 'EDUCATION')\n",
            "('Tribhuvan University', 'EDUCATION')\n",
            "('Lamar University', 'EDUCATION')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}