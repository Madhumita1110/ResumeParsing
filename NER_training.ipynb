{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rqPQfOdRswqa"
      },
      "outputs": [],
      "source": [
        "# Installing the libraries for project\n",
        "%%capture\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!pip install spacy-transformers\n",
        "!python -m spacy download en_core_web_trf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import shutil"
      ],
      "metadata": {
        "id": "PYc6ygu9x8Q1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing dataset of text documents with associated entity annotations. It uses spaCy to create a blank English language model and then converts each text into a spaCy document, while also aligning the entity annotations with the text."
      ],
      "metadata": {
        "id": "LibTm88SQgde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_v3_dataset(data, db = []):\n",
        "\n",
        "    nlp = spacy.blank('en') ## Create a blank English language model using spaCy\n",
        "    failed_record = [] ## Initialize a list to store failed records that couldn't be processed\n",
        "\n",
        "    ## If no existing DocBin is provided, create a new one\n",
        "    if not db:\n",
        "        db = DocBin()\n",
        "\n",
        "    # Loop through each text and its annotations in the data\n",
        "    for text, annot in tqdm(data):\n",
        "        doc = nlp.make_doc(text) # # Convert the raw text into a spaCy document\n",
        "        ents = [] # Initialize an empty list to store the extracted entities\n",
        "\n",
        "        # Loop through each entity annotation in the current text\n",
        "        for start, end, label in annot['entities']:\n",
        "\n",
        "           # Create a spaCy span object for each entity and try to align it with the raw text\n",
        "            span = doc.char_span(start, end, label = label, alignment_mode = 'contract')\n",
        "\n",
        "            # Check if the span was successfully created, and append it to the list of entities\n",
        "            if span is None:\n",
        "                print(f'empty entity, {text}, {annot[\"entities\"]}')\n",
        "            else:\n",
        "                ents.append(span)\n",
        "\n",
        "        # Try to set the entities of the document to the extracted entities\n",
        "        # If this fails, add the text and its annotations to the failed_record list\n",
        "        try:\n",
        "            doc.ents = ents\n",
        "        except:\n",
        "            failed_record.append((text, annot))\n",
        "\n",
        "        # Add the processed document to the DocBin\n",
        "        db.add(doc)\n",
        "    return db, failed_record  # Return the populated DocBin and the list of failed records"
      ],
      "metadata": {
        "id": "0WXoCv8TyvAM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##path to annotated resume data and list of it\n",
        "\n",
        "tagged_data = '/content/drive/MyDrive/Dissertation/tagged_data'\n",
        "list_tagged_files = os.listdir(tagged_data)"
      ],
      "metadata": {
        "id": "1H6T7hHsz9Ps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_tagged_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0PdUlHN8Qpz",
        "outputId": "7a720ca8-61c7-44b2-8d55-2174590d2259"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##path for storing resumes in spacy format\n",
        "\n",
        "output_tagged_spacy_form ='/content/drive/MyDrive/Dissertation/output_tagged_spacy_form'"
      ],
      "metadata": {
        "id": "Wx_EFUfb0j-5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting json annotated files to spacy format\n",
        "for i in tqdm(range(len(list_tagged_files))):\n",
        "  file_path = os.path.join(tagged_data,list_tagged_files[i])\n",
        "  # print(file_path)\n",
        "  with open(file_path,'r') as f:\n",
        "    data = json.load(f)\n",
        "  saving_path = os.path.join(output_tagged_spacy_form,list_tagged_files[i][:-5]+'.spacy')\n",
        "  a,b = make_v3_dataset(data['annotations'])\n",
        "  a.to_disk(saving_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtubaGN7zVx8",
        "outputId": "24af25ce-f617-4f6d-8143-4f4ad3c5162d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/119 [00:00<?, ?it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.07it/s]\n",
            "  1%|          | 1/119 [00:00<00:26,  4.53it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 32.72it/s]\n",
            "  2%|▏         | 2/119 [00:00<00:25,  4.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.58it/s]\n",
            "  3%|▎         | 3/119 [00:00<00:23,  4.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 44.75it/s]\n",
            "  3%|▎         | 4/119 [00:00<00:23,  4.91it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 35.01it/s]\n",
            "  4%|▍         | 5/119 [00:01<00:23,  4.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 25.18it/s]\n",
            "  5%|▌         | 6/119 [00:01<00:23,  4.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.01it/s]\n",
            "  6%|▌         | 7/119 [00:01<00:22,  4.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.10it/s]\n",
            "  7%|▋         | 8/119 [00:01<00:22,  4.97it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.78it/s]\n",
            "  8%|▊         | 9/119 [00:01<00:22,  4.94it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.63it/s]\n",
            "  8%|▊         | 10/119 [00:02<00:21,  5.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.25it/s]\n",
            "  9%|▉         | 11/119 [00:02<00:21,  5.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 19.54it/s]\n",
            " 10%|█         | 12/119 [00:02<00:23,  4.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 30.48it/s]\n",
            " 11%|█         | 13/119 [00:02<00:23,  4.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.06it/s]\n",
            " 12%|█▏        | 14/119 [00:02<00:22,  4.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.79it/s]\n",
            " 13%|█▎        | 15/119 [00:03<00:21,  4.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.57it/s]\n",
            " 13%|█▎        | 16/119 [00:03<00:20,  4.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 50.43it/s]\n",
            " 14%|█▍        | 17/119 [00:03<00:20,  5.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 44.72it/s]\n",
            " 15%|█▌        | 18/119 [00:03<00:19,  5.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 38.13it/s]\n",
            " 16%|█▌        | 19/119 [00:03<00:20,  4.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.55it/s]\n",
            " 17%|█▋        | 20/119 [00:04<00:19,  5.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.20it/s]\n",
            " 18%|█▊        | 21/119 [00:04<00:19,  4.94it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.16it/s]\n",
            " 18%|█▊        | 22/119 [00:04<00:19,  4.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.38it/s]\n",
            " 19%|█▉        | 23/119 [00:04<00:19,  5.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 24.93it/s]\n",
            " 20%|██        | 24/119 [00:04<00:19,  4.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 45.57it/s]\n",
            " 21%|██        | 25/119 [00:05<00:19,  4.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.92it/s]\n",
            " 22%|██▏       | 26/119 [00:05<00:18,  4.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 37.63it/s]\n",
            " 23%|██▎       | 27/119 [00:05<00:18,  4.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 31.79it/s]\n",
            " 24%|██▎       | 28/119 [00:05<00:19,  4.70it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 44.96it/s]\n",
            " 24%|██▍       | 29/119 [00:05<00:19,  4.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.00it/s]\n",
            " 25%|██▌       | 30/119 [00:06<00:18,  4.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.02it/s]\n",
            " 26%|██▌       | 31/119 [00:06<00:18,  4.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.48it/s]\n",
            " 27%|██▋       | 32/119 [00:06<00:17,  4.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.35it/s]\n",
            " 28%|██▊       | 33/119 [00:06<00:17,  5.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.50it/s]\n",
            " 29%|██▊       | 34/119 [00:06<00:17,  4.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 41.90it/s]\n",
            " 29%|██▉       | 35/119 [00:07<00:16,  5.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.18it/s]\n",
            " 30%|███       | 36/119 [00:07<00:16,  5.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.62it/s]\n",
            " 31%|███       | 37/119 [00:07<00:16,  5.09it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.07it/s]\n",
            " 32%|███▏      | 38/119 [00:07<00:15,  5.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.53it/s]\n",
            " 33%|███▎      | 39/119 [00:07<00:15,  5.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 38.41it/s]\n",
            " 34%|███▎      | 40/119 [00:08<00:15,  5.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.79it/s]\n",
            " 34%|███▍      | 41/119 [00:08<00:15,  5.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 45.10it/s]\n",
            " 35%|███▌      | 42/119 [00:08<00:14,  5.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.02it/s]\n",
            " 36%|███▌      | 43/119 [00:08<00:14,  5.24it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 31.81it/s]\n",
            " 37%|███▋      | 44/119 [00:08<00:14,  5.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 50.40it/s]\n",
            " 38%|███▊      | 45/119 [00:09<00:14,  5.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.42it/s]\n",
            " 39%|███▊      | 46/119 [00:09<00:14,  4.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.82it/s]\n",
            " 39%|███▉      | 47/119 [00:09<00:14,  5.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.03it/s]\n",
            " 40%|████      | 48/119 [00:09<00:14,  5.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.57it/s]\n",
            " 41%|████      | 49/119 [00:09<00:13,  5.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.43it/s]\n",
            " 42%|████▏     | 50/119 [00:10<00:13,  5.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.35it/s]\n",
            " 43%|████▎     | 51/119 [00:10<00:13,  4.97it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 328.94it/s]\n",
            " 44%|████▎     | 52/119 [00:10<00:14,  4.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.71it/s]\n",
            " 45%|████▍     | 53/119 [00:10<00:13,  4.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.35it/s]\n",
            " 45%|████▌     | 54/119 [00:10<00:13,  4.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 33.01it/s]\n",
            " 46%|████▌     | 55/119 [00:11<00:13,  4.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 22.14it/s]\n",
            " 47%|████▋     | 56/119 [00:11<00:14,  4.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 29.23it/s]\n",
            " 48%|████▊     | 57/119 [00:11<00:13,  4.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.37it/s]\n",
            " 49%|████▊     | 58/119 [00:11<00:13,  4.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.55it/s]\n",
            " 50%|████▉     | 59/119 [00:12<00:13,  4.54it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.38it/s]\n",
            " 50%|█████     | 60/119 [00:12<00:12,  4.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 88.71it/s]\n",
            " 51%|█████▏    | 61/119 [00:12<00:11,  4.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 22.51it/s]\n",
            " 52%|█████▏    | 62/119 [00:12<00:12,  4.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.38it/s]\n",
            " 53%|█████▎    | 63/119 [00:13<00:17,  3.24it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.49it/s]\n",
            " 54%|█████▍    | 64/119 [00:13<00:15,  3.61it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 37.92it/s]\n",
            " 55%|█████▍    | 65/119 [00:13<00:13,  3.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.05it/s]\n",
            " 55%|█████▌    | 66/119 [00:13<00:13,  4.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.88it/s]\n",
            " 56%|█████▋    | 67/119 [00:14<00:12,  4.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.60it/s]\n",
            " 57%|█████▋    | 68/119 [00:14<00:11,  4.42it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
            " 58%|█████▊    | 69/119 [00:14<00:10,  4.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 33.02it/s]\n",
            " 59%|█████▉    | 70/119 [00:14<00:10,  4.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 44.40it/s]\n",
            " 60%|█████▉    | 71/119 [00:14<00:10,  4.61it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 27.95it/s]\n",
            " 61%|██████    | 72/119 [00:15<00:10,  4.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 44.38it/s]\n",
            " 61%|██████▏   | 73/119 [00:15<00:10,  4.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 37.62it/s]\n",
            " 62%|██████▏   | 74/119 [00:15<00:09,  4.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 28.54it/s]\n",
            " 63%|██████▎   | 75/119 [00:15<00:09,  4.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 29.44it/s]\n",
            " 64%|██████▍   | 76/119 [00:16<00:09,  4.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.62it/s]\n",
            " 65%|██████▍   | 77/119 [00:16<00:08,  4.83it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 50.33it/s]\n",
            " 66%|██████▌   | 78/119 [00:16<00:08,  5.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.89it/s]\n",
            " 66%|██████▋   | 79/119 [00:16<00:08,  4.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.30it/s]\n",
            " 67%|██████▋   | 80/119 [00:16<00:07,  4.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.65it/s]\n",
            " 68%|██████▊   | 81/119 [00:16<00:07,  4.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.06it/s]\n",
            " 69%|██████▉   | 82/119 [00:17<00:07,  5.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 16.72it/s]\n",
            " 70%|██████▉   | 83/119 [00:17<00:07,  4.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.40it/s]\n",
            " 71%|███████   | 84/119 [00:17<00:07,  4.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.36it/s]\n",
            " 71%|███████▏  | 85/119 [00:17<00:06,  4.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 41.80it/s]\n",
            " 72%|███████▏  | 86/119 [00:17<00:06,  5.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 44.16it/s]\n",
            " 73%|███████▎  | 87/119 [00:18<00:06,  5.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 23.10it/s]\n",
            " 74%|███████▍  | 88/119 [00:18<00:06,  4.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 45.60it/s]\n",
            " 75%|███████▍  | 89/119 [00:18<00:05,  5.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.04it/s]\n",
            " 76%|███████▌  | 90/119 [00:18<00:05,  5.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 19.56it/s]\n",
            " 76%|███████▋  | 91/119 [00:19<00:05,  4.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 24.47it/s]\n",
            " 77%|███████▋  | 92/119 [00:19<00:05,  4.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 97.61it/s]\n",
            " 78%|███████▊  | 93/119 [00:19<00:05,  5.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.95it/s]\n",
            " 79%|███████▉  | 94/119 [00:19<00:04,  5.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.69it/s]\n",
            " 80%|███████▉  | 95/119 [00:19<00:04,  4.91it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.21it/s]\n",
            " 81%|████████  | 96/119 [00:20<00:04,  5.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.34it/s]\n",
            " 82%|████████▏ | 97/119 [00:20<00:04,  5.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 81.88it/s]\n",
            " 82%|████████▏ | 98/119 [00:20<00:04,  5.22it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 41.48it/s]\n",
            " 83%|████████▎ | 99/119 [00:20<00:03,  5.25it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 31.26it/s]\n",
            " 84%|████████▍ | 100/119 [00:20<00:03,  5.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 37.90it/s]\n",
            " 85%|████████▍ | 101/119 [00:20<00:03,  5.18it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.51it/s]\n",
            " 86%|████████▌ | 102/119 [00:21<00:03,  5.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.35it/s]\n",
            " 87%|████████▋ | 103/119 [00:21<00:03,  5.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 41.30it/s]\n",
            " 87%|████████▋ | 104/119 [00:21<00:02,  5.21it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 38.59it/s]\n",
            " 88%|████████▊ | 105/119 [00:21<00:02,  5.17it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 23.51it/s]\n",
            " 89%|████████▉ | 106/119 [00:21<00:02,  5.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.53it/s]\n",
            " 90%|████████▉ | 107/119 [00:22<00:02,  4.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.77it/s]\n",
            " 91%|█████████ | 108/119 [00:22<00:02,  5.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 50.42it/s]\n",
            " 92%|█████████▏| 109/119 [00:22<00:01,  5.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 42.94it/s]\n",
            " 92%|█████████▏| 110/119 [00:22<00:01,  5.17it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.05it/s]\n",
            " 93%|█████████▎| 111/119 [00:22<00:01,  5.25it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 25.62it/s]\n",
            " 94%|█████████▍| 112/119 [00:23<00:01,  4.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.24it/s]\n",
            " 95%|█████████▍| 113/119 [00:23<00:01,  5.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.00it/s]\n",
            " 96%|█████████▌| 114/119 [00:23<00:00,  5.18it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 20.07it/s]\n",
            " 97%|█████████▋| 115/119 [00:23<00:00,  4.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.84it/s]\n",
            " 97%|█████████▋| 116/119 [00:23<00:00,  5.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.53it/s]\n",
            " 98%|█████████▊| 117/119 [00:24<00:00,  5.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.72it/s]\n",
            " 99%|█████████▉| 118/119 [00:24<00:00,  5.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 41.93it/s]\n",
            "100%|██████████| 119/119 [00:24<00:00,  4.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividing annotated data in spacy format into training and validation sets."
      ],
      "metadata": {
        "id": "Ail01tR6tvsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the source directory where your samples are located\n",
        "source_directory = \"/content/drive/MyDrive/Dissertation/output_tagged_spacy_form\"  # Adjust the path accordingly\n",
        "\n",
        "# Define the destination directories for training and validation sets\n",
        "training_directory = \"/content/drive/MyDrive/Dissertation/training_data\"  # Adjust the path accordingly\n",
        "validation_directory = \"/content/drive/MyDrive/Dissertation/validation_data\"  # Adjust the path accordingly\n",
        "\n",
        "# Create the destination directories if they don't exist\n",
        "os.makedirs(training_directory, exist_ok=True)\n",
        "os.makedirs(validation_directory, exist_ok=True)\n",
        "\n",
        "# Get a list of files in the source directory\n",
        "files = os.listdir(source_directory)\n",
        "\n",
        "# Sort the files to ensure consistent splitting\n",
        "files.sort()\n",
        "\n",
        "# Separate files into training and validation sets\n",
        "for idx, filename in enumerate(files, 1):\n",
        "    # If the file index is a multiple of 6, move it to the validation set\n",
        "    if idx % 6 == 0:\n",
        "        source_path = os.path.join(source_directory, filename)\n",
        "        destination_path = os.path.join(validation_directory, filename)\n",
        "    # Otherwise, move it to the training set\n",
        "    else:\n",
        "        source_path = os.path.join(source_directory, filename)\n",
        "        destination_path = os.path.join(training_directory, filename)\n",
        "\n",
        "    # Move the file to the appropriate directory\n",
        "    shutil.move(source_path, destination_path)\n"
      ],
      "metadata": {
        "id": "_COFOhlz3iSc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization setting\n",
        "!python -m spacy init fill-config /content/drive/MyDrive/Dissertation/base_config.cfg /content/drive/MyDrive/Dissertation/config.cfg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAyeQ3xz-Rm9",
        "outputId": "6abb1ff7-b218-4511-b778-6fab6dee11d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-23 21:46:14.473245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/drive/MyDrive/Dissertation/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train -g 0 /content/drive/MyDrive/Dissertation/config.cfg  --output /content/drive/MyDrive/Dissertation/generated_model --paths.train /content/drive/MyDrive/Dissertation/output_tagged_spacy_form --paths.dev /content/drive/MyDrive/Dissertation/validation_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkjBz_AAQZkF",
        "outputId": "642940e0-25f7-4b91-ecca-114f944c3e83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-24 09:24:20.791725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/Dissertation/generated_model\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-07-24 09:24:24,964] [INFO] Set up nlp object from config\n",
            "[2023-07-24 09:24:24,980] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2023-07-24 09:24:24,984] [INFO] Created vocabulary\n",
            "[2023-07-24 09:24:24,984] [INFO] Finished initializing nlp object\n",
            "Downloading (…)lve/main/config.json: 100% 481/481 [00:00<00:00, 2.78MB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 10.9MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 1.90MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 6.09MB/s]\n",
            "Downloading model.safetensors: 100% 499M/499M [00:01<00:00, 373MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2023-07-24 09:24:57,663] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        1545.09   2302.84    3.77    1.97   43.65    0.04\n",
            "  2     200      253728.91  67010.54   57.91   61.79   54.49    0.58\n",
            "  4     400      224434.47  17526.08   64.52   66.82   62.36    0.65\n",
            "  6     600        6134.94   7597.03   81.27   74.43   89.50    0.81\n",
            "  8     800        4648.15   6722.77   80.99   71.60   93.22    0.81\n",
            " 11    1000        8263.18   5551.26   88.37   91.26   85.67    0.88\n",
            " 13    1200        2566.26   3847.85   81.10   95.14   70.68    0.81\n",
            " 15    1400        1966.46   2905.61   92.01   89.05   95.19    0.92\n",
            " 17    1600        2228.90   2551.85   89.97   93.30   86.87    0.90\n",
            " 20    1800        1387.35   1992.89   93.78   91.21   96.50    0.94\n",
            " 22    2000         802.56   1246.72   93.64   92.34   94.97    0.94\n",
            " 24    2200         653.57   1210.36   94.10   93.05   95.19    0.94\n",
            " 26    2400         645.91   1039.74   94.34   92.99   95.73    0.94\n",
            " 29    2600         483.24    871.91   95.19   93.01   97.48    0.95\n",
            " 31    2800         387.01    670.51   94.13   91.10   97.37    0.94\n",
            " 33    3000         348.63    764.21   95.51   94.44   96.61    0.96\n",
            " 35    3200         353.64    644.96   95.12   93.27   97.05    0.95\n",
            " 38    3400         293.59    582.20   94.90   93.24   96.61    0.95\n",
            " 40    3600         336.52    574.50   95.28   93.47   97.16    0.95\n",
            " 42    3800         175.42    564.74   95.31   95.10   95.51    0.95\n",
            " 44    4000         264.94    514.72   95.17   93.46   96.94    0.95\n",
            " 47    4200         214.87    450.23   95.24   93.19   97.37    0.95\n",
            " 49    4400         171.69    429.76   95.45   93.40   97.59    0.95\n",
            " 51    4600         232.39    539.74   96.03   95.36   96.72    0.96\n",
            " 53    4800         265.00    431.80   95.36   94.14   96.61    0.95\n",
            " 56    5000         162.81    419.93   95.54   93.88   97.26    0.96\n",
            " 58    5200         186.68    407.03   95.51   94.53   96.50    0.96\n",
            " 60    5400         123.35    466.78   96.16   95.18   97.16    0.96\n",
            " 62    5600         126.73    361.33   96.02   94.40   97.70    0.96\n",
            " 65    5800         122.39    375.09   96.06   94.69   97.48    0.96\n",
            " 67    6000         121.76    355.02   95.52   94.25   96.83    0.96\n",
            " 69    6200          66.97    419.84   95.72   94.75   96.72    0.96\n",
            " 71    6400         123.64    348.50   95.54   93.78   97.37    0.96\n",
            " 74    6600          57.27    304.67   96.03   94.21   97.92    0.96\n",
            " 76    6800          78.31    300.50   95.86   94.29   97.48    0.96\n",
            " 78    7000          78.57    414.16   95.83   94.95   96.72    0.96\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/Dissertation/generated_model/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy evaluate /content/drive/MyDrive/Dissertation/generated_model/model-best /content/drive/MyDrive/Dissertation/output_tagged_spacy_form --gpu-id 0 -o output_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDlyqVfhCAL1",
        "outputId": "1435f271-efc8-419f-8bb5-1c7415893b46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-24 11:02:27.718072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   93.87 \n",
            "NER R   95.98 \n",
            "NER F   94.91 \n",
            "SPEED   7181  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                 P       R       F\n",
            "JOB TITLE    98.32   99.15   98.73\n",
            "SKILL        93.30   97.06   95.14\n",
            "EXPERIENCE   96.44   95.72   96.07\n",
            "EDUCATION    94.56   88.96   91.67\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to output_metrics\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy evaluate /content/drive/MyDrive/Dissertation/generated_model/model-best /content/drive/MyDrive/Dissertation/validation_data --gpu-id 0 -o output_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHVMto04iU5q",
        "outputId": "f7c76f63-8288-4969-8262-3052f251a8f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-24 11:04:46.224574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   95.18 \n",
            "NER R   97.16 \n",
            "NER F   96.16 \n",
            "SPEED   4537  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                  P        R        F\n",
            "JOB TITLE    100.00   100.00   100.00\n",
            "EXPERIENCE   100.00   100.00   100.00\n",
            "EDUCATION     94.64    85.48    89.83\n",
            "SKILL         94.58    98.84    96.66\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to output_metrics\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('/content/drive/MyDrive/Dissertation/generated_model/model-best')"
      ],
      "metadata": {
        "id": "1aKkxUg4CbzO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test example\n",
        "main_str = ['''MASTER DATA MANAGER\n",
        "Experience\n",
        "Master Data Manager\n",
        "\n",
        ",\n",
        "01/2019\n",
        "\n",
        "to\n",
        "Current\n",
        "\n",
        "Company Name\n",
        "\n",
        "â€“\n",
        "City\n",
        "\n",
        ",\n",
        "State\n",
        "\n",
        "Aligning 100+ supply chain-related master data attributes to ensure the following guidelines are met:.\n",
        "Data Stewardship - Appropriate business units and ownership established to validate appropriate values, definitions and\n",
        "impact\n",
        "documentation for all master data fields.\n",
        "Data Quality - Applicable controls are set in conjecture with IT to ensure that a proactive approach is taken to new\n",
        "master data.\n",
        "Additionally, RPA process planned for Phase 2 to automate structured data entry and maintenance.\n",
        "Data Integrity/Data Warehousing - Structure business logic to ensure BOMs and other data relationships are both\n",
        "accessible and built as an\n",
        "asset for the business.\n",
        "Additionally, a Data Sync SOP was established for GS1 standardization.\n",
        "Reporting - Automate data quality reporting for executive staff to ensure 99.8% compliance is adhered to throughout\n",
        "the organization.\n",
        "Additionally, provide ad-hoc tools for the business to leverage clean data cubes.\n",
        "Data Governance Committee - Oversee executive strategy in institutional master data to commit to trusted, accurate, structured\n",
        "and\n",
        "meaningful master data.\n",
        "Engaging applicable stakeholders to promote data governance, data architect, data stewardship and\n",
        "data security the data governance\n",
        "committee oversees the framework for complex supply chain manufacturing operations.\n",
        "Director of Information Technology\n",
        "\n",
        ",\n",
        "01/2017\n",
        "\n",
        "to\n",
        "01/2019\n",
        "\n",
        "Company Name\n",
        "\n",
        "â€“\n",
        "City\n",
        "\n",
        ",\n",
        "State\n",
        "\n",
        "Supply Chain Management - Warehouse, 3PL, Food Services, Served as the corporate Project Manager, overseeing all implementations\n",
        "(WMS, ERP, QMS, CMMS, infrastructure).\n",
        "Responsibilities included progress reporting, budget control, task delegation, plan creation, vendor coordination, etc.\n",
        "Developed a range of documents and performed project selection tasks such as workflow process maps, system integration\n",
        "documents,\n",
        "infrastructure topology, organizational policies, GDPR, UAT, gap analysis, best fit models and user training manuals.\n",
        "Deployed and managed BI products to leverage company-wide data for decisionmakers, proactive analysis, and real-time resource\n",
        "planning.\n",
        "Utilizing SSRS/PowerBI to analyze sets of data across multiple databases, automate value-add reporting to 3PL clients,\n",
        "visualize KPIs thru\n",
        "the organization, create workflows for document automation and create alerts for various business units.\n",
        "Launched a high-performance data warehouses and virtual machines to store, integrate, analyze, and report on enterprise data.\n",
        "An\n",
        "array of SSAS cubes were deployed to allow for end-user ad-hoc tabular reports.\n",
        "Additionally, a complex network of interfaces\n",
        "between 6+ enterprise systems, 4 SQL databases, 1 Oracle database, and other enterprise\n",
        "systems (file server, exchange, EDI, etc)\n",
        "was implemented to support the ETL process.\n",
        "Executing infrastructure refresh for a 200,000 sqft industrial/production facility.\n",
        "The deployment includes an array of 15 switches,\n",
        "1,000 cable runs, racking, 100 AP, 300 cameras, NVRs, controllers, and creating floor\n",
        "plans and topology documents.\n",
        "Controlled a $2MM IT budget, short-term and long-term strategies, and CapEx justification across the business.\n",
        "Including selecting\n",
        "and negotiating with vendors, promoting operational process improvement, instituting best practices, and developing IT\n",
        "roadmaps\n",
        "and strategic plans.\n",
        "On track to reduce IT spend by $250K by renegotiating vendor contracts, consolidating cloud services,\n",
        "implementing automation tools and\n",
        "upgrading legacy systems.\n",
        "Responsible for a team of IT professionals and vendors assigned to all corporate and local office systems, including ERP, WMS,\n",
        "logistics\n",
        "systems, data centers, servers and storage, PCs, mobile devices, BDR, telecom, and help desk.\n",
        "Reduced IT service desk's\n",
        "response time and resolution time while increasing knowledge base and reducing reoccurring tickets by over\n",
        "50%.\n",
        "Information Technology Governance & Steering Committee (ITGSC) - Reporting directly to the board of directors, the\n",
        "ITGSC provided\n",
        "strategic direction in aligning IT projects to shareholder interest and long-term targets.\n",
        "While overseeing the\n",
        "committee the cross-functional team guided 12 business units across operations, sales, and manufacturing.\n",
        "Additionally, the ITGSC\n",
        "aided in risk management, business continuity, and organizational SOPs.\n",
        "NatJan Solutions (Facility Management - Retail, Medical, Grocery Sectors.\n",
        "Information Technology and Analytics Manager\n",
        "\n",
        ",\n",
        "01/2014\n",
        "\n",
        "to\n",
        "01/2017\n",
        "\n",
        "Implemented process within external ERP portal to monetize 1000's of vendors to generate lean revenue based on financial and\n",
        "operational\n",
        "data analysis.\n",
        "This program is estimated to bring in $325,000 in its first year, an 8% increase in margin.\n",
        "Created ad-hoc and scheduled BI (PowerBI/SSRS) reports to visualize critical client metrics and reports, internal performance\n",
        "KPIs,\n",
        "operational resource planning, asset and revenue forecasting, P/L summaries, expense budgets, etc.\n",
        "Spearheaded national RFP bids of multi-million-dollar procurement deals with several Fortune 500 retail, medical, and education\n",
        "companies.\n",
        "Tasks included sales analysis, margin analysis, multivariable pricing structures, vendor acquisition, developing process\n",
        "flow and establishing\n",
        "KPI reporting for clientele and internal use.\n",
        "Designed ad-hoc SQL views, stored proceduresand reports to address company-wide data analysis and modeling.Utilized advanced VBA programming and automation software to manage two billing systems, saving an estimated $75,000 in Salary\n",
        "Expenses in 2015, translating to a 40% reduction in departmental spending.\n",
        "Reported on a wide array of KPIs on operations, sales, accounting, and vendors via dashboard-style (BI/SSRS) reports for COO,\n",
        "CFO,\n",
        "Vice President of Sales and Account Manager use.\n",
        "Overhauled all company technology from on-premise systems to an array of cloud solutions, including replacing hardware and\n",
        "migrating\n",
        "servers and databases, this renovation saves ~$108,000 per year and provides long-term scalability.\n",
        "01/2015\n",
        "\n",
        "to\n",
        "01/2017\n",
        "\n",
        "Company Name\n",
        "\n",
        "â€“\n",
        "City\n",
        "\n",
        ",\n",
        "State\n",
        "\n",
        "Co-Founded indoor, hydroponic farming company in South Jersey.\n",
        "Bringing a hyper-local product to the Camden and Philadelphia\n",
        "region HGF generated $100K in its first year via a strategic relationship with\n",
        "the premier food management service in Philadelphia,\n",
        "local restaurants, farmer's markets, and Whole Foods retail chain.\n",
        "Sales & Operations Planning (S&OP) - The S&OP team managed bi-directional interactions between sales, marketing,\n",
        "production, and\n",
        "finance.\n",
        "S&OP committee oversaw finished goods inventory controls, marketing vs financial targets, raw material\n",
        "and supplier management, logistics\n",
        "and human capital planning.\n",
        "Additionally, benchmarks for product mix, SKU management, and\n",
        "forecast vs demand vs actual alignment.\n",
        "Operations - Oversaw the general operations of the farm, including assigning day-to-day jobs, tracking yield results, establishing\n",
        "daily work\n",
        "schedules, and tracking transplanting/harvesting schedules.\n",
        "Automation Systems - Implemented an array of sensors to control environmental and nutrient levels.\n",
        "Utilizing this data and\n",
        "automation systems we drove automated pH balancing, nutrient leveling, temperature control, ventilation systems, and\n",
        "established\n",
        "a strong exception-based manufacturing operation.\n",
        "Finance - Oversaw all aspects of the financial responsibilities including establishing a point of sales systems, P/L reports, budgeting\n",
        "for OpEx\n",
        "and CapEx schedules, coordinating with lenders, insurance institutions and annual tax reports.\n",
        "SOPs - Instituted standard operating procedures to ensure quality standards are maintained and product consistency is maintained.\n",
        "Work History\n",
        "Master Data Manager\n",
        "\n",
        ",\n",
        "01/2019\n",
        "\n",
        "to\n",
        "Current\n",
        "\n",
        "Company Name\n",
        "\n",
        "â€“\n",
        "City\n",
        "\n",
        ",\n",
        "State\n",
        "\n",
        "Aligning 100+ supply chain-related master data attributes to ensure the following guidelines are met:.\n",
        "Data Stewardship - Appropriate business units and ownership established to validate appropriate values, definitions and\n",
        "impact\n",
        "documentation for all master data fields.\n",
        "Data Quality - Applicable controls are set in conjecture with IT to ensure that a proactive approach is taken to new\n",
        "master data.\n",
        "Additionally, RPA process planned for Phase 2 to automate structured data entry and maintenance.\n",
        "Data Integrity/Data Warehousing - Structure business logic to ensure BOMs and other data relationships are both\n",
        "accessible and built as an\n",
        "asset for the business.\n",
        "Additionally, a Data Sync SOP was established for GS1 standardization.\n",
        "Reporting - Automate data quality reporting for executive staff to ensure 99.8% compliance is adhered to throughout\n",
        "the organization.\n",
        "Additionally, provide ad-hoc tools for the business to leverage clean data cubes.\n",
        "Data Governance Committee - Oversee executive strategy in institutional master data to commit to trusted, accurate, structured\n",
        "and\n",
        "meaningful master data.\n",
        "Engaging applicable stakeholders to promote data governance, data architect, data stewardship and\n",
        "data security the data governance\n",
        "committee oversees the framework for complex supply chain manufacturing operations.\n",
        "Director of Information Technology\n",
        "\n",
        ",\n",
        "01/2017\n",
        "\n",
        "to\n",
        "01/2019\n",
        "\n",
        "Company Name\n",
        "\n",
        "â€“\n",
        "City\n",
        "\n",
        ",\n",
        "State\n",
        "\n",
        "Supply Chain Management - Warehouse, 3PL, Food Services, Served as the corporate Project Manager, overseeing all implementations\n",
        "(WMS, ERP, QMS, CMMS, infrastructure).\n",
        "Responsibilities included progress reporting, budget control, task delegation, plan creation, vendor coordination, etc.\n",
        "Developed a range of documents and performed project selection tasks such as workflow process maps, system integration\n",
        "documents,\n",
        "infrastructure topology, organizational policies, GDPR, UAT, gap analysis, best fit models and user training manuals.\n",
        "Deployed and managed BI products to leverage company-wide data for decisionmakers, proactive analysis, and real-time resource\n",
        "planning.\n",
        "Utilizing SSRS/PowerBI to analyze sets of data across multiple databases, automate value-add reporting to 3PL clients,\n",
        "visualize KPIs thru\n",
        "the organization, create workflows for document automation and create alerts for various business units.\n",
        "Launched a high-performance data warehouses and virtual machines to store, integrate, analyze, and report on enterprise data.\n",
        "An\n",
        "array of SSAS cubes were deployed to allow for end-user ad-hoc tabular reports.\n",
        "Additionally, a complex network of interfaces\n",
        "between 6+ enterprise systems, 4 SQL databases, 1 Oracle database, and other enterprise\n",
        "systems (file server, exchange, EDI, etc)\n",
        "was implemented to support the ETL process.\n",
        "Executing infrastructure refresh for a 200,000 sqft industrial/production facility.\n",
        "The deployment includes an array of 15 switches,\n",
        "1,000 cable runs, racking, 100 AP, 300 cameras, NVRs, controllers, and creating floor\n",
        "plans and topology documents.\n",
        "Controlled a $2MM IT budget, short-term and long-term strategies, and CapEx justification across the business.Including selecting\n",
        "and negotiating with vendors, promoting operational process improvement, instituting best practices, and developing IT\n",
        "roadmaps\n",
        "and strategic plans.\n",
        "On track to reduce IT spend by $250K by renegotiating vendor contracts, consolidating cloud services,\n",
        "implementing automation tools and\n",
        "upgrading legacy systems.\n",
        "Responsible for a team of IT professionals and vendors assigned to all corporate and local office systems, including ERP, WMS,\n",
        "logistics\n",
        "systems, data centers, servers and storage, PCs, mobile devices, BDR, telecom, and help desk.\n",
        "Reduced IT service desk's\n",
        "response time and resolution time while increasing knowledge base and reducing reoccurring tickets by over\n",
        "50%.\n",
        "Information Technology Governance & Steering Committee (ITGSC) - Reporting directly to the board of directors, the\n",
        "ITGSC provided\n",
        "strategic direction in aligning IT projects to shareholder interest and long-term targets.\n",
        "While overseeing the\n",
        "committee the cross-functional team guided 12 business units across operations, sales, and manufacturing.\n",
        "Additionally, the ITGSC\n",
        "aided in risk management, business continuity, and organizational SOPs.\n",
        "NatJan Solutions (Facility Management - Retail, Medical, Grocery Sectors.\n",
        "Information Technology and Analytics Manager\n",
        "\n",
        ",\n",
        "01/2014\n",
        "\n",
        "to\n",
        "01/2017\n",
        "\n",
        "Implemented process within external ERP portal to monetize 1000's of vendors to generate lean revenue based on financial and\n",
        "operational\n",
        "data analysis.\n",
        "This program is estimated to bring in $325,000 in its first year, an 8% increase in margin.\n",
        "Created ad-hoc and scheduled BI (PowerBI/SSRS) reports to visualize critical client metrics and reports, internal performance\n",
        "KPIs,\n",
        "operational resource planning, asset and revenue forecasting, P/L summaries, expense budgets, etc.\n",
        "Spearheaded national RFP bids of multi-million-dollar procurement deals with several Fortune 500 retail, medical, and education\n",
        "companies.\n",
        "Tasks included sales analysis, margin analysis, multivariable pricing structures, vendor acquisition, developing process\n",
        "flow and establishing\n",
        "KPI reporting for clientele and internal use.\n",
        "Designed ad-hoc SQL views, stored procedures and reports to address company-wide data analysis and modeling.\n",
        "Utilized advanced VBA programming and automation software to manage two billing systems, saving an estimated $75,000 in Salary\n",
        "Expenses in 2015, translating to a 40% reduction in departmental spending.\n",
        "Reported on a wide array of KPIs on operations, sales, accounting, and vendors via dashboard-style (BI/SSRS) reports for COO,\n",
        "CFO,\n",
        "Vice President of Sales and Account Manager use.\n",
        "Overhauled all company technology from on-premise systems to an array of cloud solutions, including replacing hardware and\n",
        "migrating\n",
        "servers and databases, this renovation saves ~$108,000 per year and provides long-term scalability.\n",
        "01/2015\n",
        "\n",
        "to\n",
        "01/2017\n",
        "\n",
        "Company Name\n",
        "\n",
        "â€“\n",
        "City\n",
        "\n",
        ",\n",
        "State\n",
        "\n",
        "Co-Founded indoor, hydroponic farming company in South Jersey.\n",
        "Bringing a hyper-local product to the Camden and Philadelphia\n",
        "region HGF generated $100K in its first year via a strategic relationship with\n",
        "the premier food management service in Philadelphia,\n",
        "local restaurants, farmer's markets, and Whole Foods retail chain.\n",
        "Sales & Operations Planning (S&OP) - The S&OP team managed bi-directional interactions between sales, marketing,\n",
        "production, and\n",
        "finance.\n",
        "S&OP committee oversaw finished goods inventory controls, marketing vs financial targets, raw material\n",
        "and supplier management, logistics\n",
        "and human capital planning.\n",
        "Additionally, benchmarks for product mix, SKU management, and\n",
        "forecast vs demand vs actual alignment.\n",
        "Operations - Oversaw the general operations of the farm, including assigning day-to-day jobs, tracking yield results, establishing\n",
        "daily work\n",
        "schedules, and tracking transplanting/harvesting schedules.\n",
        "Automation Systems - Implemented an array of sensors to control environmental and nutrient levels.\n",
        "Utilizing this data and\n",
        "automation systems we drove automated pH balancing, nutrient leveling, temperature control, ventilation systems, and\n",
        "established\n",
        "a strong exception-based manufacturing operation.\n",
        "Finance - Oversawall aspects of the financial responsibilities including establishing a point of sales systems, P/L reports, budgeting\n",
        "for OpEx\n",
        "and CapEx schedules, coordinating with lenders, insurance institutions and annual tax reports.\n",
        "SOPs - Instituted standard operating procedures to ensure quality standards are maintained and product consistency is maintained.\n",
        "Education\n",
        "Bachelor of Science\n",
        "\n",
        ":\n",
        "Management of Information Systems\n",
        "\n",
        ",\n",
        "2017\n",
        "\n",
        "Associates of Science\n",
        "\n",
        ":\n",
        "Accounting\n",
        "\n",
        ",\n",
        "2015\n",
        "\n",
        "Rowan College\n",
        "\n",
        "Pursuing Project Management Professional (PMP) certification\n",
        "\n",
        "Rowan University\n",
        "\n",
        "Summary\n",
        "Zeel Patel is an Information Technology Manager with a focus on IT transformation and process improvement currently looking for opportunities in\n",
        "the greater Miami, FL metropolitan area. Zeel has experience working with corporate data in the areas of data presentation, structured and\n",
        "unsecured datasets, data mining, statistical analysis, UI creation, data warehouse management, and assessing data quality. Additionally, Zeel's\n",
        "diverse background has allowed him to succeed in a project management and IT management role. In this role, Zeel has engaged in holistic\n",
        "business analysis, process improvement, strategic planning, budgeting, contract negotiations, vendor relations, resource management, instituting\n",
        "best practices, and overseeing/implementing multiple enterprise systems (ERP, WMS, CRM, WOM, QMS, SCP).\n",
        "Highlights\n",
        "Automation tools, HTML, RetailMicrosoft Office Suite with deep Office 365, Dynamics 365, Project, PowerApps, PowerBI,\n",
        "Flow,\n",
        "Sharepoint, Excel, Access, Intune, Visio, EMS, and Azure proficiency\n",
        "Programming/Databases: SQL (SSRS, SSIS, SSAS), VBA, DAX, HTML, CSS, VBA,\n",
        "VB.NET, R, Powershell, Python, Oracle\n",
        "Business Intelligence Packages: PowerBI, Qlik (QlikView/QlikSense), SiSense, Tableau,\n",
        "Datorama, Yellowfin, Crystal, SSRS\n",
        "Strong knowledge of AWS, Azure, Cisco Switch Management, VMWare, Hyper-V, RDP,\n",
        "Automation Anywhere, Active Directory,\n",
        "And hardware and software administration for iOS, Android, Windows, Red Hat Linux, RF\n",
        "devices\n",
        "VB.NET, EDI, Procurement, Ventilation\n",
        "Accounting, ERP, Programming, Visio\n",
        "Active Directory, ETL, Progress, VBA\n",
        "Premier, Facility Management, Project Management, Workflow\n",
        "Ad, Finance, Python\n",
        "AP, Financial, Quality\n",
        "Approach, Floor plans, Real-time\n",
        "Architect, Forecasting, Red Hat Linux\n",
        "Automate, Functional, Renovation\n",
        "Automation, Help desk, Reporting\n",
        "Automation tools, HTML, Retail\n",
        "Billing systems, Information\n",
        "Technology, RFP\n",
        "Budgeting, Insurance, Risk\n",
        "management\n",
        "Budgets, Inventory, Sales\n",
        "Budget, Logic, Sales analysis\n",
        "BI, Logistics, Servers\n",
        "Business Intelligence, Marketing,\n",
        "SOP\n",
        "Cable, Access, SQL\n",
        "Cisco, Excel, Strategy\n",
        "Hardware, Exchange, Strategic\n",
        "Contracts, Microsoft Office Suite,\n",
        "Strategic plans\n",
        "Crystal, Office, Structured\n",
        "CSS, Sharepoint, Supplier\n",
        "management\n",
        "Clientele, Windows, Supply chain\n",
        "Client, Negotiating, Supply Chain\n",
        "Management\n",
        "Clients, Enterprise, Switches\n",
        "Data analysis, Network, Switch\n",
        "Data entry, Oracle, System\n",
        "integration\n",
        "Data analysis and modeling, Oracle\n",
        "database, Tableau\n",
        "Data warehouses, Organizational,\n",
        "Tax\n",
        "Databases, Cameras, User training\n",
        "Data Warehousing, Policies,\n",
        "Telecom\n",
        "Direction, Pricing, Translating\n",
        "Documentation, Process\n",
        "improvement, Upgrading\n",
        "Skills\n",
        "Microsoft Office Suite with deep Office 365, Dynamics 365, Project, PowerApps, PowerBI, Flow,\n",
        "SSharepoint, Excel, Access, Intune, Visio, EMS, and Azure proficiency\n",
        "PProgramming/Databases: SQL (SSRS, SSIS, SSAS), VBA, DAX, HTML, CSS, VBA, VB.NET, R, Powershell, Python, Oracle\n",
        "BBusiness Intelligence Packages: PowerBI, Qlik (QlikView/QlikSense), SiSense, Tableau, Datorama, Yellowfin, Crystal, SSRS\n",
        "SStrong knowledge of AWS, Azure, Cisco Switch Management, VMWare, Hyper-V, RDP, Automation Anywhere, Active Directory,\n",
        "Aand hardware and software administration for iOS, Android, Windows, Red Hat Linux, RF devices,\n",
        "VB.NET, accounting, Active Directory, premier, ad, AP, approach, architect, Automate, Automation, automation tools, billing systems,\n",
        "budgeting, budgets, budget, BI, Business Intelligence, cable, Cisco, hardware, contracts, Crystal, CSS, clientele, client, clients, data analysis, data\n",
        "entry, data analysis and modeling, data warehouses, Databases, Data Warehousing, direction, documentation, EDI, ERP, ETL, Facility\n",
        "Management, Finance, financial, floor plans, forecasting, functional, help desk, HTML, Information Technology, insurance, inventory, logic,\n",
        "logistics, marketing, Access, Excel, exchange, Microsoft Office Suite, Office, Sharepoint, Windows, negotiating, enterprise, network, Oracle,\n",
        "Oracle database, organizational, cameras, policies, pricing, process improvement, procurement, Programming, progress, Project Management,\n",
        "Python, Quality, real-time, Red Hat Linux, renovation, reporting, Retail, RFP, risk management, Sales, sales analysis, servers, SOP, SQL,\n",
        "strategy, strategic, strategic plans, structured, supplier management, supply chain, Supply Chain Management, switches, Switch, system integration,\n",
        "Tableau, tax, user training, telecom, translating, upgrading, ventilation, Visio, VBA, workflow''']"
      ],
      "metadata": {
        "id": "IW36SbS-Cz--"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in nlp.pipe(main_str, disable=[\"tagger\", \"parser\"]):\n",
        "  for ent in doc.ents:\n",
        "    print((ent.text,ent.label_))\n",
        "    # print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBFX8gj8DM1w",
        "outputId": "6c68b193-207b-4221-83b5-f418294f38c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('MASTER DATA MANAGER', 'JOB TITLE')\n",
            "('Master Data Manager\\n\\n,\\n01/2019\\n\\nto\\nCurrent', 'EXPERIENCE')\n",
            "('Director of Information Technology\\n\\n,\\n01/2017\\n\\nto\\n01/2019', 'EXPERIENCE')\n",
            "('Information Technology and Analytics Manager\\n\\n,\\n01/2014\\n\\nto\\n01/2017', 'EXPERIENCE')\n",
            "('01/2015\\n\\nto\\n01/2017', 'EXPERIENCE')\n",
            "('Master Data Manager\\n\\n,\\n01/2019\\n\\nto\\nCurrent', 'EXPERIENCE')\n",
            "('Director of Information Technology\\n\\n,\\n01/2017\\n\\nto\\n01/2019', 'EXPERIENCE')\n",
            "('Information Technology and Analytics Manager\\n\\n,\\n01/2014\\n\\nto\\n01/2017', 'EXPERIENCE')\n",
            "('Bachelor of Science\\n\\n:\\nManagement of Information Systems', 'EDUCATION')\n",
            "('Associates of Science\\n\\n:\\nAccounting', 'EDUCATION')\n",
            "('Rowan College', 'EDUCATION')\n",
            "('Pursuing Project Management Professional', 'EDUCATION')\n",
            "('Rowan University', 'EDUCATION')\n",
            "('VBA', 'SKILL')\n",
            "('DAX', 'SKILL')\n",
            "('HTML', 'SKILL')\n",
            "('CSS', 'SKILL')\n",
            "('VB.NET', 'SKILL')\n",
            "('R', 'SKILL')\n",
            "('Powershell', 'SKILL')\n",
            "('Python', 'SKILL')\n",
            "('Oracle', 'SKILL')\n",
            "('PowerBI', 'SKILL')\n",
            "('Qlik (QlikView/QlikSense)', 'SKILL')\n",
            "('SiSense', 'SKILL')\n",
            "('Tableau', 'SKILL')\n",
            "('Datorama', 'SKILL')\n",
            "('Yellowfin', 'SKILL')\n",
            "('Crystal', 'SKILL')\n",
            "('SSRS\\nStrong knowledge of AWS', 'SKILL')\n",
            "('Azure', 'SKILL')\n",
            "('Cisco Switch Management', 'SKILL')\n",
            "('VMWare', 'SKILL')\n",
            "('Hyper-V', 'SKILL')\n",
            "('RDP', 'SKILL')\n",
            "('Automation Anywhere', 'SKILL')\n",
            "('Active Directory', 'SKILL')\n",
            "('hardware and software administration', 'SKILL')\n",
            "('iOS', 'SKILL')\n",
            "('Android', 'SKILL')\n",
            "('Windows', 'SKILL')\n",
            "('Red Hat Linux', 'SKILL')\n",
            "('RF\\ndevices', 'SKILL')\n",
            "('VB.NET', 'SKILL')\n",
            "('EDI', 'SKILL')\n",
            "('Procurement', 'SKILL')\n",
            "('Ventilation\\nAccounting', 'SKILL')\n",
            "('ERP', 'SKILL')\n",
            "('Programming', 'SKILL')\n",
            "('Visio\\nActive Directory', 'SKILL')\n",
            "('ETL', 'SKILL')\n",
            "('Progress', 'SKILL')\n",
            "('VBA\\nPremier', 'SKILL')\n",
            "('Facility Management', 'SKILL')\n",
            "('Project Management', 'SKILL')\n",
            "('Workflow\\nAd', 'SKILL')\n",
            "('Finance', 'SKILL')\n",
            "('Python\\nAP', 'SKILL')\n",
            "('Quality\\nApproach', 'SKILL')\n",
            "('Floor plans', 'SKILL')\n",
            "('Real-time\\nArchitect', 'SKILL')\n",
            "('Forecasting', 'SKILL')\n",
            "('Red Hat Linux\\nAutomate', 'SKILL')\n",
            "('Functional', 'SKILL')\n",
            "('Renovation\\nAutomation', 'SKILL')\n",
            "('Help desk', 'SKILL')\n",
            "('Reporting\\nAutomation tools', 'SKILL')\n",
            "('HTML', 'SKILL')\n",
            "('Retail\\nBilling systems', 'SKILL')\n",
            "('Information\\nTechnology', 'SKILL')\n",
            "('RFP\\nBudgeting', 'SKILL')\n",
            "('Insurance', 'SKILL')\n",
            "('Risk\\nmanagement', 'SKILL')\n",
            "('Inventory', 'SKILL')\n",
            "('Sales\\nBudget', 'SKILL')\n",
            "('Logistics', 'SKILL')\n",
            "('Marketing', 'SKILL')\n",
            "('SOP\\nCable', 'SKILL')\n",
            "('SQL\\nCisco', 'SKILL')\n",
            "('Excel', 'SKILL')\n",
            "('Strategy\\nHardware', 'SKILL')\n",
            "('Exchange', 'SKILL')\n",
            "('Strategic\\nContracts', 'SKILL')\n",
            "('Microsoft Office Suite', 'SKILL')\n",
            "('Crystal', 'SKILL')\n",
            "('Structured\\nCSS', 'SKILL')\n",
            "('Supplier\\nmanagement\\nClientele', 'SKILL')\n",
            "('Supply chain\\nClient', 'SKILL')\n",
            "('Negotiating', 'SKILL')\n",
            "('Supply Chain\\nManagement\\nClients', 'SKILL')\n",
            "('Enterprise', 'SKILL')\n",
            "('Switches\\nData analysis', 'SKILL')\n",
            "('Network', 'SKILL')\n",
            "('Switch\\nData entry', 'SKILL')\n",
            "('Oracle', 'SKILL')\n",
            "('System\\nintegration\\nData analysis', 'SKILL')\n",
            "('Oracle', 'SKILL')\n",
            "('Tableau\\nData warehouses', 'SKILL')\n",
            "('Cameras', 'SKILL')\n",
            "('User training\\nData Warehousing', 'SKILL')\n",
            "('Policies', 'SKILL')\n",
            "('Telecom\\nDirection', 'SKILL')\n",
            "('Pricing', 'SKILL')\n",
            "('Translating\\nDocumentation', 'SKILL')\n",
            "('Process\\nimprovement', 'SKILL')\n",
            "('Microsoft Office Suite', 'SKILL')\n",
            "('deep Office 365', 'SKILL')\n",
            "('Dynamics 365', 'SKILL')\n",
            "('Project', 'SKILL')\n",
            "('PowerApps', 'SKILL')\n",
            "('PowerBI', 'SKILL')\n",
            "('Flow', 'SKILL')\n",
            "('SSharepoint', 'SKILL')\n",
            "('Excel', 'SKILL')\n",
            "('Access', 'SKILL')\n",
            "('Intune', 'SKILL')\n",
            "('Visio', 'SKILL')\n",
            "('EMS', 'SKILL')\n",
            "('Azure proficiency\\nPProgramming', 'SKILL')\n",
            "('SQL (SSRS, SSIS, SSAS', 'SKILL')\n",
            "('VBA', 'SKILL')\n",
            "('DAX', 'SKILL')\n",
            "('HTML', 'SKILL')\n",
            "('CSS', 'SKILL')\n",
            "('VBA', 'SKILL')\n",
            "('VB.NET', 'SKILL')\n",
            "('R', 'SKILL')\n",
            "('Powershell', 'SKILL')\n",
            "('Python', 'SKILL')\n",
            "('Oracle\\nBBusiness Intelligence Packages', 'SKILL')\n",
            "('PowerBI', 'SKILL')\n",
            "('Qlik (QlikView/QlikSense)', 'SKILL')\n",
            "('SiSense', 'SKILL')\n",
            "('Tableau', 'SKILL')\n",
            "('Datorama', 'SKILL')\n",
            "('Yellowfin', 'SKILL')\n",
            "('Crystal', 'SKILL')\n",
            "('SSRS\\nSStrong', 'SKILL')\n",
            "('Azure', 'SKILL')\n",
            "('Cisco Switch Management', 'SKILL')\n",
            "('VMWare', 'SKILL')\n",
            "('Hyper-V', 'SKILL')\n",
            "('RDP', 'SKILL')\n",
            "('Automation Anywhere', 'SKILL')\n",
            "('Active Directory', 'SKILL')\n",
            "('hardware and software administration', 'SKILL')\n",
            "('Android', 'SKILL')\n",
            "('Windows', 'SKILL')\n",
            "('Red Hat Linux', 'SKILL')\n",
            "('RF devices', 'SKILL')\n",
            "('VB.NET', 'SKILL')\n",
            "('accounting', 'SKILL')\n",
            "('Active Directory', 'SKILL')\n",
            "('premier', 'SKILL')\n",
            "('ad', 'SKILL')\n",
            "('AP', 'SKILL')\n",
            "('approach', 'SKILL')\n",
            "('architect', 'SKILL')\n",
            "('Automate', 'SKILL')\n",
            "('Automation', 'SKILL')\n",
            "('automation tools', 'SKILL')\n",
            "('billing systems', 'SKILL')\n",
            "('budgeting', 'SKILL')\n",
            "('BI', 'SKILL')\n",
            "('Business Intelligence', 'SKILL')\n",
            "('cable', 'SKILL')\n",
            "('Cisco', 'SKILL')\n",
            "('hardware', 'SKILL')\n",
            "('contracts', 'SKILL')\n",
            "('Crystal', 'SKILL')\n",
            "('CSS', 'SKILL')\n",
            "('data analysis', 'SKILL')\n",
            "('data\\nentry', 'SKILL')\n",
            "('data analysis and modeling', 'SKILL')\n",
            "('data warehouses', 'SKILL')\n",
            "('Databases', 'SKILL')\n",
            "('Data Warehousing', 'SKILL')\n",
            "('documentation', 'SKILL')\n",
            "('EDI', 'SKILL')\n",
            "('ERP', 'SKILL')\n",
            "('ETL', 'SKILL')\n",
            "('Facility\\nManagement', 'SKILL')\n",
            "('Finance', 'SKILL')\n",
            "('financial', 'SKILL')\n",
            "('floor plans', 'SKILL')\n",
            "('forecasting', 'SKILL')\n",
            "('functional', 'SKILL')\n",
            "('help desk', 'SKILL')\n",
            "('HTML', 'SKILL')\n",
            "('Information Technology', 'SKILL')\n",
            "('insurance', 'SKILL')\n",
            "('inventory', 'SKILL')\n",
            "('logic', 'SKILL')\n",
            "('marketing', 'SKILL')\n",
            "('Excel', 'SKILL')\n",
            "('Microsoft Office Suite', 'SKILL')\n",
            "('Office', 'SKILL')\n",
            "('Sharepoint', 'SKILL')\n",
            "('negotiating', 'SKILL')\n",
            "('Oracle', 'SKILL')\n",
            "('policies', 'SKILL')\n",
            "('pricing', 'SKILL')\n",
            "('process improvement', 'SKILL')\n",
            "('procurement', 'SKILL')\n",
            "('Programming', 'SKILL')\n",
            "('Project Management', 'SKILL')\n",
            "('Python', 'SKILL')\n",
            "('Quality', 'SKILL')\n",
            "('real-time', 'SKILL')\n",
            "('Red Hat Linux', 'SKILL')\n",
            "('renovation', 'SKILL')\n",
            "('reporting', 'SKILL')\n",
            "('Retail', 'SKILL')\n",
            "('risk management', 'SKILL')\n",
            "('sales analysis', 'SKILL')\n",
            "('SOP', 'SKILL')\n",
            "('SQL', 'SKILL')\n",
            "('supplier management', 'SKILL')\n",
            "('supply chain', 'SKILL')\n",
            "('Supply Chain Management', 'SKILL')\n",
            "('switches', 'SKILL')\n",
            "('Switch', 'SKILL')\n",
            "('system integration', 'SKILL')\n",
            "('Tableau', 'SKILL')\n",
            "('tax', 'SKILL')\n",
            "('telecom', 'SKILL')\n",
            "('translating', 'SKILL')\n",
            "('upgrading', 'SKILL')\n",
            "('ventilation', 'SKILL')\n",
            "('VBA', 'SKILL')\n",
            "('workflow', 'SKILL')\n"
          ]
        }
      ]
    }
  ]
}